---
layout: post
title: "The Hubble constant that isn't"
date: 2015-01-10 11:23:13
summary: "Why the Hubble constant must decrease over time, assuming that the relative speed of distant galaxies is proportional to distance - and why this should have been blindingly obvious from the start."
categories: blog sci
---
I had an interesting discussion with my physics teacher yesterday about the Hubble constant. I realised that the constant must decrease over time, assuming that the velocity of an object is proportional to its distance, as per Hubble's law. I had trouble putting this into words, but I've looked into it further and it seems that this is not only true but is also quite obvious when looked at from another perspective. There are two different ways to explain this phenomenon: with maths or with words.

## with maths

Ignoring the subtleties of the inflationary epoch during the Big Bang, it's fair to say that the distance (*x*) between the observer and a distant galaxy is proportional to time since the Big Bang (where *t*=0 is the Big Bang.) This lets us define some function to relate time and the distance to some reference galaxy, like so:

<div style="text-align: center">
  <img src="http://latex.codecogs.com/png.latex?%5Cdpi%7B120%7D%20D%28t%29%3Dkt" alt="D(t)=kt"/>
</div>

This explanation also works if *D(t)* is some polynomial function of *t*. Now, The derivative of *D(t)* with respect to time is:

<div style="text-align: center">
  <img src="https://latex.codecogs.com/gif.latex?%5Cdpi%7B120%7D%20D%27%28t%29%3Dk" alt="D'(t)=k"/>
</div>

Derivative of displacement with respect to time, so this tells us that the reference galaxy has a constant velocity. The Hubble constant is the ratio of velocity to distance, like so:

<div style="text-align: center">
  <img src="https://latex.codecogs.com/gif.latex?%5Cdpi%7B120%7D%20%5Cfrac%7BD%27%28t%29%7D%7BD%28t%29%7D%3DH_%7B0%7D%3D%5Cfrac%7Bk%7D%7Bkt%7D%3Dt%5E%7B-1%7D" alt="D'(t)/D(t)=H_0=k/kt=t^-1"/>
</div>

This tells us that the Hubble constant is just the reciprocal of time since the start of the universe, so of course it cannot be constant! The subscript zero in the notation for the constant implies that this is the value *at the current time*. Indeed, the reciprocal of the Hubble constant is what allows us to calculate the age of the Universe (or approximate it), so it would be nonsensical if it were constant, as that would imply the Universe has existed for an infinite amount of time.

If the Hubble constant was constant in time, then the growth of the Universe would be exponential (as only e^x has the property of being proportional to its derivative) which contradicts current theories regarding the age of the Universe. This doesn't imply that it's impossible, of course - I'm open to new ideas in such areas - but would require another radical re-think of theories about the origin and ultimate fate of the universe.

## with words

If you're less mathematically inclined, or don't find this sufficient enough to explain the idea, then an explanation in prose might be more useful to you. Remember that the Hubble constant is just a relationship between how far something is away from you, and how fast it is travelling.

Imagine a race of two people as an analogy for two galaxies, between person A and person B , where the latter travels twice as fast. They both start at the same point, like how everything in the observable universe started at a point also. Now imagine the finish line of the race: this is our Megaparsec. Person B crosses the finish line in half the time that Person A does, as they are going twice as fast. This means that although they both reach the finish line, they are travelling at different speeds when they do so. As the distance to the finish line does not change, this means that the ratio between the speed of the runner and distance to the finish line cannot be the same for both.

Another way to describe this is the excellent analogy by the Cornell University astronomy page[^1] for which I have highlighted the important part in bold:

> Even though the universe is "accelerating" in the sense that each galaxy moves faster as time goes on, the Hubble constant is actually decreasing with time -- in other words, the rate at which space is expanding, measured at a point which is at a fixed distance from us, gets smaller as time goes on. **If we keep our eyes on an individual galaxy as it moves away from us, we will see it accelerate, but if we keep our eyes on a fixed point in space and watch many different galaxies go past that point, each galaxy's speed will be slower than the one before it.** (As a very rough analogy, the universe behaves like a river with rapids. If you put a boat in the river and allow it to be carried by the flow, it will accelerate as it moves downstream and enters the rapids. But if you sit on the bank and measure the speed of the water at one location, it changes based on an entirely different set of factors -- for example, the rate at which the supply of water from upstream is changing. It is possible for the water speed at your location to decrease with time, even though each boat that you release accelerates as it heads into the rapids.) Because of this effect, if light is able to "swim against the tide" and remain at a roughly constant distance with respect to us (as would happen if it is emitted from a galaxy moving away from us at the speed of light), then as time goes on and the Hubble constant decreases, it will eventually be able to gain ground, "swim upstream" and traverse the necessary distance of space to reach us.

## cosmological horizon

This exploration of the Hubble constant lets us observe that the rate of expansion (velocity) at a fixed distance away from us is actually decreasing, as mentioned in the latter part of the quote. This means that if a galaxy which is moving at *c* away from us emits light toward us (such as at the boundary of the observable universe, the *cosmological horizon*), then that light will eventually make it to the observer, as the rate of expansion at the edge of the universe decreases with time. This means that the boundaries of the observable universe are pushed back somewhat from the point where galaxies recede from us at the speed of light.

## conclusion

Due to the situation described in this post, I feel that it is misleading to name the ratio of velocity to distance the Hubble constant. Something more apt would be the *Hubble metric* or *Hubble ratio* - or even described for what it is, ie. the reciprocal of the age of the Universe. Describing something which is constant in space but not in time as a constant is definitely confusing without sufficient explanation, and I feel that the GCSE and A-level curriculum doesn't emphasise this point well enough.

[^1]: http://curious.astro.cornell.edu/question.php?number=575
